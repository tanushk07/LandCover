dirs:
  data_dir: data
  train_dir: train
  test_dir: test
  image_dir: images
  mask_dir: masks
  model_dir: models
  output_dir: output/segformer_experiment
  pred_mask_dir: predicted_masks
  pred_plot_dir: prediction_plots
  log_dir: logs

vars:
  train_log_name: segformer_train.log
  test_log_name: segformer_test.log
  log_level: "INFO"
  file_type: ".tif"

  patch_size: 512
  discard_rate: 0.9
  batch_size: 14                     # good for RTX 5080
  num_workers: 4

  model_arch: "SegFormer"
  model_name: trained_landcover_segformer_segformer-b0_epochs60_patch512_batch14.pth
  encoder: "segformer-b0"
  encoder_weights: "imagenet"
  activation: "softmax2d"
  is_transformer: true

  optimizer_choice: "AdamW"
  init_lr: 0.00006                   # perfect base LR for MiT-B0
  weight_decay: 0.05
  betas: [0.9, 0.999]
  reduce_lr_by_factor: 0.5
  patience_epochs_before_reducing_lr: 8
  lr_reduce_threshold: 0.0001
  minimum_lr: 1e-6
  warmup_epochs: 2                   # smoother start for transformers
  epochs: 30                         # 20 is too short; 60 trains to full potential
  gradient_clip_value: 1.0

  use_amp: true                      # mixed precision = faster and lighter
  grad_accum_steps: 1
  dropout: 0.1                       # minor regularization
  label_smoothing: 0.05              # improves class balance
  device: "cuda"

  all_classes: ["background", "building", "woodland", "water", "road"]
  train_classes:["background", "building", "woodland", "water", "road"]
  test_classes: ["background", "building", "woodland", "water", "road"]
